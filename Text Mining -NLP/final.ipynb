{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "import pandas as pd\n",
    "#from emoticons import EmoticonDetector\n",
    "import re as regex\n",
    "import numpy as np\n",
    "import plotly\n",
    "from plotly import graph_objs\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from time import time\n",
    "import gensim\n",
    "\n",
    "# plotly configuration\n",
    "plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterData_Initialize():\n",
    "    data = []\n",
    "    processed_data = []\n",
    "    wordlist = []\n",
    "\n",
    "    data_model = None\n",
    "    data_labels = None\n",
    "    is_testing = False\n",
    "    \n",
    "    def initialize(self, csv_file, is_testing_set=False, from_cached=None):\n",
    "        if from_cached is not None:\n",
    "            self.data_model = pd.read_csv(from_cached)\n",
    "            return\n",
    "\n",
    "        self.is_testing = is_testing_set\n",
    "\n",
    "        if not is_testing_set:\n",
    "            self.data = pd.read_csv(csv_file, header=0, names=[\"id\", \"emotion\", \"text\"])\n",
    "            self.data = self.data[self.data[\"emotion\"].isin([\"positive\", \"negative\", \"neutral\"])]\n",
    "        else:\n",
    "            self.data = pd.read_csv(csv_file, header=0, names=[\"id\", \"text\"],dtype={\"id\":\"int64\",\"text\":\"str\"},nrows=4000)\n",
    "            not_null_text = 1 ^ pd.isnull(self.data[\"text\"])\n",
    "            not_null_id = 1 ^ pd.isnull(self.data[\"id\"])\n",
    "            self.data = self.data.loc[not_null_id & not_null_text, :]\n",
    "\n",
    "        self.processed_data = self.data\n",
    "        self.wordlist = []\n",
    "        self.data_model = None\n",
    "        self.data_labels = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>635769805279248384</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>635930169241374720</td>\n",
       "      <td>neutral</td>\n",
       "      <td>IOS 9 App Transport Security. Mm need to check...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>635950258682523648</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Mar if you have an iOS device, you should down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>636030803433009153</td>\n",
       "      <td>negative</td>\n",
       "      <td>@jimmie_vanagon my phone does not run on lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>636100906224848896</td>\n",
       "      <td>positive</td>\n",
       "      <td>Not sure how to start your publication on iOS?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id   emotion  \\\n",
       "0  635769805279248384  negative   \n",
       "1  635930169241374720   neutral   \n",
       "2  635950258682523648   neutral   \n",
       "3  636030803433009153  negative   \n",
       "4  636100906224848896  positive   \n",
       "\n",
       "                                                text  \n",
       "0                                      Not Available  \n",
       "1  IOS 9 App Transport Security. Mm need to check...  \n",
       "2  Mar if you have an iOS device, you should down...  \n",
       "3  @jimmie_vanagon my phone does not run on lates...  \n",
       "4  Not sure how to start your publication on iOS?...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TwitterData_Initialize()\n",
    "data.initialize(\"/Users/harsha/Desktop/train.csv\")\n",
    "data.processed_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "bar",
         "x": [
          "negative",
          "neutral",
          "positive"
         ],
         "y": [
          956,
          2125,
          2888
         ]
        }
       ],
       "layout": {
        "title": "Sentiment type distribution in training set"
       }
      },
      "text/html": [
       "<div id=\"9a5bcf19-294d-49f3-9175-a3005dcee05d\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"9a5bcf19-294d-49f3-9175-a3005dcee05d\", [{\"y\": [956, 2125, 2888], \"x\": [\"negative\", \"neutral\", \"positive\"], \"type\": \"bar\"}], {\"title\": \"Sentiment type distribution in training set\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"9a5bcf19-294d-49f3-9175-a3005dcee05d\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"9a5bcf19-294d-49f3-9175-a3005dcee05d\", [{\"y\": [956, 2125, 2888], \"x\": [\"negative\", \"neutral\", \"positive\"], \"type\": \"bar\"}], {\"title\": \"Sentiment type distribution in training set\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = data.processed_data\n",
    "neg = len(df[df[\"emotion\"] == \"negative\"])\n",
    "pos = len(df[df[\"emotion\"] == \"positive\"])\n",
    "neu = len(df[df[\"emotion\"] == \"neutral\"])\n",
    "dist = [\n",
    "    graph_objs.Bar(\n",
    "        x=[\"negative\",\"neutral\",\"positive\"],\n",
    "        y=[neg, neu, pos],\n",
    ")]\n",
    "plotly.offline.iplot({\"data\":dist, \"layout\":graph_objs.Layout(title=\"Sentiment type distribution in training set\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterCleanuper:\n",
    "    def iterate(self):\n",
    "        for cleanup_method in [self.remove_urls,\n",
    "                               self.remove_usernames,\n",
    "                               self.remove_na,\n",
    "                               self.remove_special_chars,\n",
    "                               self.remove_numbers]:\n",
    "            yield cleanup_method\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_by_regex(tweets, regexp):\n",
    "        tweets.loc[:, \"text\"].replace(regexp, \"\", inplace=True)\n",
    "        return tweets\n",
    "\n",
    "    def remove_urls(self, tweets):\n",
    "        return TwitterCleanuper.remove_by_regex(tweets, regex.compile(r\"http.?://[^\\s]+[\\s]?\"))\n",
    "\n",
    "    def remove_na(self, tweets):\n",
    "        return tweets[tweets[\"text\"] != \"Not Available\"]\n",
    "\n",
    "    def remove_special_chars(self, tweets):  # it unrolls the hashtags to normal words\n",
    "        for remove in map(lambda r: regex.compile(regex.escape(r)), [\",\", \":\", \"\\\"\", \"=\", \"&\", \";\", \"%\", \"$\",\n",
    "                                                                     \"@\", \"%\", \"^\", \"*\", \"(\", \")\", \"{\", \"}\",\n",
    "                                                                     \"[\", \"]\", \"|\", \"/\", \"\\\\\", \">\", \"<\", \"-\",\n",
    "                                                                     \"!\", \"?\", \".\", \"'\",\n",
    "                                                                     \"--\", \"---\", \"#\"]):\n",
    "            tweets.loc[:, \"text\"].replace(remove, \"\", inplace=True)\n",
    "        return tweets\n",
    "\n",
    "    def remove_usernames(self, tweets):\n",
    "        return TwitterCleanuper.remove_by_regex(tweets, regex.compile(r\"@[^\\s]+[\\s]?\"))\n",
    "\n",
    "    def remove_numbers(self, tweets):\n",
    "        return TwitterCleanuper.remove_by_regex(tweets, regex.compile(r\"\\s?[0-9]+\\.?[0-9]*\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterData_Cleansing(TwitterData_Initialize):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        \n",
    "    def cleanup(self, cleanuper):\n",
    "        t = self.processed_data\n",
    "        for cleanup_method in cleanuper.iterate():\n",
    "            if not self.is_testing:\n",
    "                t = cleanup_method(t)\n",
    "            else:\n",
    "                if cleanup_method.__name__ != \"remove_na\":\n",
    "                    t = cleanup_method(t)\n",
    "\n",
    "        self.processed_data = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterData_TokenStem(TwitterData_Cleansing):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        \n",
    "    def stem(self, stemmer=nltk.PorterStemmer()):\n",
    "        def stem_and_join(row):\n",
    "            row[\"text\"] = list(map(lambda str: stemmer.stem(str.lower()), row[\"text\"]))\n",
    "            return row\n",
    "\n",
    "        self.processed_data = self.processed_data.apply(stem_and_join, axis=1)\n",
    "\n",
    "    def tokenize(self, tokenizer=nltk.word_tokenize):\n",
    "        def tokenize_row(row):\n",
    "            row[\"text\"] = tokenizer(row[\"text\"])\n",
    "            row[\"tokenized_text\"] = [] + row[\"text\"]\n",
    "            return row\n",
    "\n",
    "        self.processed_data = self.processed_data.apply(tokenize_row, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>635769805279248384</td>\n",
       "      <td>negative</td>\n",
       "      <td>[not, avail]</td>\n",
       "      <td>[Not, Available]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>635930169241374720</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[io, 9, app, transport, secur, ., mm, need, to...</td>\n",
       "      <td>[IOS, 9, App, Transport, Security, ., Mm, need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>635950258682523648</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[mar, if, you, have, an, io, devic, ,, you, sh...</td>\n",
       "      <td>[Mar, if, you, have, an, iOS, device, ,, you, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>636030803433009153</td>\n",
       "      <td>negative</td>\n",
       "      <td>[@, jimmie_vanagon, my, phone, doe, not, run, ...</td>\n",
       "      <td>[@, jimmie_vanagon, my, phone, does, not, run,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>636100906224848896</td>\n",
       "      <td>positive</td>\n",
       "      <td>[not, sure, how, to, start, your, public, on, ...</td>\n",
       "      <td>[Not, sure, how, to, start, your, publication,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id   emotion  \\\n",
       "0  635769805279248384  negative   \n",
       "1  635930169241374720   neutral   \n",
       "2  635950258682523648   neutral   \n",
       "3  636030803433009153  negative   \n",
       "4  636100906224848896  positive   \n",
       "\n",
       "                                                text  \\\n",
       "0                                       [not, avail]   \n",
       "1  [io, 9, app, transport, secur, ., mm, need, to...   \n",
       "2  [mar, if, you, have, an, io, devic, ,, you, sh...   \n",
       "3  [@, jimmie_vanagon, my, phone, doe, not, run, ...   \n",
       "4  [not, sure, how, to, start, your, public, on, ...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0                                   [Not, Available]  \n",
       "1  [IOS, 9, App, Transport, Security, ., Mm, need...  \n",
       "2  [Mar, if, you, have, an, iOS, device, ,, you, ...  \n",
       "3  [@, jimmie_vanagon, my, phone, does, not, run,...  \n",
       "4  [Not, sure, how, to, start, your, publication,...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TwitterData_TokenStem(data)\n",
    "data.tokenize()\n",
    "data.stem()\n",
    "data.processed_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 4297), ('.', 3831), (':', 2848), (',', 2527), ('to', 2493)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = Counter()\n",
    "for idx in data.processed_data.index:\n",
    "    words.update(data.processed_data.loc[idx, \"text\"])\n",
    "\n",
    "words.most_common(5)\n",
    "\n",
    "# output:\n",
    "# [('the', 3744), ('to', 2477), ('i', 1667), ('a', 1620), ('on', 1557)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 3831), (':', 2848), (',', 2527), ('@', 2268), ('http', 1912)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords=nltk.corpus.stopwords.words(\"english\")\n",
    "whitelist = [\"n't\", \"not\"]\n",
    "for idx, stop_word in enumerate(stopwords):\n",
    "    if stop_word not in whitelist:\n",
    "        del words[stop_word]\n",
    "words.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterData_Wordlist(TwitterData_TokenStem):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        \n",
    "    whitelist = [\"n't\",\"not\"]\n",
    "    wordlist = []\n",
    "        \n",
    "    def build_wordlist(self, min_occurrences=3, max_occurences=500, stopwords=nltk.corpus.stopwords.words(\"english\"),\n",
    "                       whitelist=None):\n",
    "        self.wordlist = []\n",
    "        whitelist = self.whitelist if whitelist is None else whitelist\n",
    "        import os\n",
    "        if os.path.isfile(\"data\\\\wordlist.csv\"):\n",
    "            word_df = pd.read_csv(\"data\\\\wordlist.csv\")\n",
    "            word_df = word_df[word_df[\"occurrences\"] > min_occurrences]\n",
    "            self.wordlist = list(word_df.loc[:, \"word\"])\n",
    "            return\n",
    "\n",
    "        words = Counter()\n",
    "        for idx in self.processed_data.index:\n",
    "            words.update(self.processed_data.loc[idx, \"text\"])\n",
    "\n",
    "        for idx, stop_word in enumerate(stopwords):\n",
    "            if stop_word not in whitelist:\n",
    "                del words[stop_word]\n",
    "\n",
    "        word_df = pd.DataFrame(data={\"word\": [k for k, v in words.most_common() if min_occurrences < v < max_occurences],\n",
    "                                     \"occurrences\": [v for k, v in words.most_common() if min_occurrences < v < max_occurences]},\n",
    "                               columns=[\"word\", \"occurrences\"])\n",
    "\n",
    "        word_df.to_csv(\"data\\\\wordlist.csv\", index_label=\"idx\")\n",
    "        self.wordlist = [k for k, v in words.most_common() if min_occurrences < v < max_occurences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = TwitterData_Wordlist(data)\n",
    "data.build_wordlist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "x": [
          347,
          349,
          349,
          349,
          352,
          362,
          376,
          385,
          393,
          406,
          433
         ],
         "y": [
          "'m",
          "-",
          "like",
          "get",
          "1st",
          "time",
          "see",
          ")",
          "''",
          "``",
          "&"
         ]
        }
       ],
       "layout": {
        "title": "Top words in built wordlist"
       }
      },
      "text/html": [
       "<div id=\"2ab873a9-b08d-4661-975d-72d005964d89\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"2ab873a9-b08d-4661-975d-72d005964d89\", [{\"y\": [\"'m\", \"-\", \"like\", \"get\", \"1st\", \"time\", \"see\", \")\", \"''\", \"``\", \"&\"], \"x\": [347, 349, 349, 349, 352, 362, 376, 385, 393, 406, 433], \"type\": \"bar\", \"orientation\": \"h\"}], {\"title\": \"Top words in built wordlist\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"2ab873a9-b08d-4661-975d-72d005964d89\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"2ab873a9-b08d-4661-975d-72d005964d89\", [{\"y\": [\"'m\", \"-\", \"like\", \"get\", \"1st\", \"time\", \"see\", \")\", \"''\", \"``\", \"&\"], \"x\": [347, 349, 349, 349, 352, 362, 376, 385, 393, 406, 433], \"type\": \"bar\", \"orientation\": \"h\"}], {\"title\": \"Top words in built wordlist\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = pd.read_csv(\"data\\\\wordlist.csv\")\n",
    "x_words = list(words.loc[0:10,\"word\"])\n",
    "x_words.reverse()\n",
    "y_occ = list(words.loc[0:10,\"occurrences\"])\n",
    "y_occ.reverse()\n",
    "\n",
    "dist = [\n",
    "    graph_objs.Bar(\n",
    "        x=y_occ,\n",
    "        y=x_words,\n",
    "        orientation=\"h\"\n",
    ")]\n",
    "plotly.offline.iplot({\"data\":dist, \"layout\":graph_objs.Layout(title=\"Top words in built wordlist\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterData_BagOfWords(TwitterData_Wordlist):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        self.wordlist = previous.wordlist\n",
    "    \n",
    "    def build_data_model(self):\n",
    "        label_column = []\n",
    "        if not self.is_testing:\n",
    "            label_column = [\"label\"]\n",
    "\n",
    "        columns = label_column + list(\n",
    "            map(lambda w: w + \"_bow\",self.wordlist))\n",
    "        labels = []\n",
    "        rows = []\n",
    "        for idx in self.processed_data.index:\n",
    "            current_row = []\n",
    "\n",
    "            if not self.is_testing:\n",
    "                # add label\n",
    "                current_label = self.processed_data.loc[idx, \"emotion\"]\n",
    "                labels.append(current_label)\n",
    "                current_row.append(current_label)\n",
    "\n",
    "            # add bag-of-words\n",
    "            tokens = set(self.processed_data.loc[idx, \"text\"])\n",
    "            for _, word in enumerate(self.wordlist):\n",
    "                current_row.append(1 if word in tokens else 0)\n",
    "\n",
    "            rows.append(current_row)\n",
    "\n",
    "        self.data_model = pd.DataFrame(rows, columns=columns)\n",
    "        self.data_labels = pd.Series(labels)\n",
    "        return self.data_model, self.data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>&amp;_bow</th>\n",
       "      <th>``_bow</th>\n",
       "      <th>''_bow</th>\n",
       "      <th>)_bow</th>\n",
       "      <th>see_bow</th>\n",
       "      <th>time_bow</th>\n",
       "      <th>1st_bow</th>\n",
       "      <th>get_bow</th>\n",
       "      <th>like_bow</th>\n",
       "      <th>...</th>\n",
       "      <th>nigga_bow</th>\n",
       "      <th>rare_bow</th>\n",
       "      <th>tag_bow</th>\n",
       "      <th>weather_bow</th>\n",
       "      <th>champ_bow</th>\n",
       "      <th>ed_bow</th>\n",
       "      <th>alexi_bow</th>\n",
       "      <th>troubl_bow</th>\n",
       "      <th>boot_bow</th>\n",
       "      <th>emerg_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  &_bow  ``_bow  ''_bow  )_bow  see_bow  time_bow  1st_bow  \\\n",
       "0  negative      0       0       0      0        0         0        0   \n",
       "1   neutral      0       0       0      0        0         0        0   \n",
       "2   neutral      0       0       0      0        0         0        0   \n",
       "3  negative      0       0       0      0        0         1        0   \n",
       "4  positive      0       0       0      0        0         0        0   \n",
       "\n",
       "   get_bow  like_bow    ...      nigga_bow  rare_bow  tag_bow  weather_bow  \\\n",
       "0        0         0    ...              0         0        0            0   \n",
       "1        0         0    ...              0         0        0            0   \n",
       "2        0         0    ...              0         0        0            0   \n",
       "3        0         0    ...              0         0        0            0   \n",
       "4        0         0    ...              0         0        0            0   \n",
       "\n",
       "   champ_bow  ed_bow  alexi_bow  troubl_bow  boot_bow  emerg_bow  \n",
       "0          0       0          0           0         0          0  \n",
       "1          0       0          0           0         0          0  \n",
       "2          0       0          0           0         0          0  \n",
       "3          0       0          0           0         0          0  \n",
       "4          0       0          0           0         0          0  \n",
       "\n",
       "[5 rows x 2273 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TwitterData_BagOfWords(data)\n",
    "bow, labels = data.build_data_model()\n",
    "bow.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "positive",
         "type": "bar",
         "x": [
          "see",
          "'m",
          "time",
          "&",
          ")",
          "friday",
          "get",
          "1st",
          "``",
          "''",
          "like",
          "plan",
          "trump",
          "obama",
          "(",
          "-"
         ],
         "y": [
          246,
          198,
          183,
          169,
          169,
          169,
          161,
          132,
          151,
          146,
          128,
          30,
          29,
          57,
          124,
          145
         ]
        },
        {
         "name": "negative",
         "type": "bar",
         "x": [
          "see",
          "'m",
          "time",
          "&",
          ")",
          "friday",
          "get",
          "1st",
          "``",
          "''",
          "like",
          "plan",
          "trump",
          "obama",
          "(",
          "-"
         ],
         "y": [
          38,
          42,
          47,
          54,
          31,
          17,
          55,
          85,
          77,
          76,
          73,
          60,
          60,
          59,
          39,
          33
         ]
        },
        {
         "name": "neutral",
         "type": "bar",
         "x": [
          "see",
          "'m",
          "time",
          "&",
          ")",
          "friday",
          "get",
          "1st",
          "``",
          "''",
          "like",
          "plan",
          "trump",
          "obama",
          "(",
          "-"
         ],
         "y": [
          79,
          83,
          114,
          118,
          139,
          82,
          118,
          124,
          144,
          142,
          133,
          48,
          75,
          80,
          136,
          128
         ]
        }
       ],
       "layout": {
        "title": "Most common words across sentiments"
       }
      },
      "text/html": [
       "<div id=\"93311c04-2eb6-48bb-8a8a-d1b16de9c46e\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"93311c04-2eb6-48bb-8a8a-d1b16de9c46e\", [{\"y\": [246, 198, 183, 169, 169, 169, 161, 132, 151, 146, 128, 30, 29, 57, 124, 145], \"x\": [\"see\", \"'m\", \"time\", \"&\", \")\", \"friday\", \"get\", \"1st\", \"``\", \"''\", \"like\", \"plan\", \"trump\", \"obama\", \"(\", \"-\"], \"type\": \"bar\", \"name\": \"positive\"}, {\"y\": [38, 42, 47, 54, 31, 17, 55, 85, 77, 76, 73, 60, 60, 59, 39, 33], \"x\": [\"see\", \"'m\", \"time\", \"&\", \")\", \"friday\", \"get\", \"1st\", \"``\", \"''\", \"like\", \"plan\", \"trump\", \"obama\", \"(\", \"-\"], \"type\": \"bar\", \"name\": \"negative\"}, {\"y\": [79, 83, 114, 118, 139, 82, 118, 124, 144, 142, 133, 48, 75, 80, 136, 128], \"x\": [\"see\", \"'m\", \"time\", \"&\", \")\", \"friday\", \"get\", \"1st\", \"``\", \"''\", \"like\", \"plan\", \"trump\", \"obama\", \"(\", \"-\"], \"type\": \"bar\", \"name\": \"neutral\"}], {\"title\": \"Most common words across sentiments\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"93311c04-2eb6-48bb-8a8a-d1b16de9c46e\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"93311c04-2eb6-48bb-8a8a-d1b16de9c46e\", [{\"y\": [246, 198, 183, 169, 169, 169, 161, 132, 151, 146, 128, 30, 29, 57, 124, 145], \"x\": [\"see\", \"'m\", \"time\", \"&\", \")\", \"friday\", \"get\", \"1st\", \"``\", \"''\", \"like\", \"plan\", \"trump\", \"obama\", \"(\", \"-\"], \"type\": \"bar\", \"name\": \"positive\"}, {\"y\": [38, 42, 47, 54, 31, 17, 55, 85, 77, 76, 73, 60, 60, 59, 39, 33], \"x\": [\"see\", \"'m\", \"time\", \"&\", \")\", \"friday\", \"get\", \"1st\", \"``\", \"''\", \"like\", \"plan\", \"trump\", \"obama\", \"(\", \"-\"], \"type\": \"bar\", \"name\": \"negative\"}, {\"y\": [79, 83, 114, 118, 139, 82, 118, 124, 144, 142, 133, 48, 75, 80, 136, 128], \"x\": [\"see\", \"'m\", \"time\", \"&\", \")\", \"friday\", \"get\", \"1st\", \"``\", \"''\", \"like\", \"plan\", \"trump\", \"obama\", \"(\", \"-\"], \"type\": \"bar\", \"name\": \"neutral\"}], {\"title\": \"Most common words across sentiments\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped = bow.groupby([\"label\"]).sum()\n",
    "words_to_visualize = []\n",
    "sentiments = [\"positive\",\"negative\",\"neutral\"]\n",
    "#get the most 7 common words for every sentiment\n",
    "for sentiment in sentiments:\n",
    "    words = grouped.loc[sentiment,:]\n",
    "    words.sort_values(inplace=True,ascending=False)\n",
    "    for w in words.index[:7]:\n",
    "        if w not in words_to_visualize:\n",
    "            words_to_visualize.append(w)\n",
    "            \n",
    "            \n",
    "#visualize it\n",
    "plot_data = []\n",
    "for sentiment in sentiments:\n",
    "    plot_data.append(graph_objs.Bar(\n",
    "            x = [w.split(\"_\")[0] for w in words_to_visualize],\n",
    "            y = [grouped.loc[sentiment,w] for w in words_to_visualize],\n",
    "            name = sentiment\n",
    "    ))\n",
    "    \n",
    "plotly.offline.iplot({\n",
    "        \"data\":plot_data,\n",
    "        \"layout\":graph_objs.Layout(title=\"Most common words across sentiments\")\n",
    "    })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "seed = 666\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_classifier(X_train, y_train, X_test, y_test, classifier):\n",
    "    log(\"\")\n",
    "    log(\"===============================================\")\n",
    "    classifier_name = str(type(classifier).__name__)\n",
    "    log(\"Testing \" + classifier_name)\n",
    "    now = time()\n",
    "    list_of_labels = sorted(list(set(y_train)))\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    log(\"Learing time {0}s\".format(time() - now))\n",
    "    now = time()\n",
    "    predictions = model.predict(X_test)\n",
    "    log(\"Predicting time {0}s\".format(time() - now))\n",
    "\n",
    "    precision = precision_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    recall = recall_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    log(\"=================== Results ===================\")\n",
    "    log(\"            Negative     Neutral     Positive\")\n",
    "    log(\"F1       \" + str(f1))\n",
    "    log(\"Precision\" + str(precision))\n",
    "    log(\"Recall   \" + str(recall))\n",
    "    log(\"Accuracy \" + str(accuracy))\n",
    "    log(\"===============================================\")\n",
    "\n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "def log(x):\n",
    "    #can be used to write to log file\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================\n",
      "Testing BernoulliNB\n",
      "Learing time 0.427387952805s\n",
      "Predicting time 0.110918998718s\n",
      "=================== Results ===================\n",
      "            Negative     Neutral     Positive\n",
      "F1       [ 0.40236686  0.41992883  0.69707842]\n",
      "Precision[ 0.46363636  0.48559671  0.62672811]\n",
      "Recall   [ 0.3554007   0.36990596  0.7852194 ]\n",
      "Accuracy 0.568397543272\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow.iloc[:, 1:], bow.iloc[:, 0],\n",
    "                                                    train_size=0.7, stratify=bow.iloc[:, 0],\n",
    "                                                    random_state=seed)\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, BernoulliNB())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC \n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48352875488553881"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'             precision    recall  f1-score   support\\n\\n   negative       0.44      0.28      0.34       287\\n    neutral       0.48      0.41      0.44       638\\n   positive       0.63      0.78      0.70       866\\n\\navg / total       0.55      0.57      0.55      1791\\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "classification_report(y_test,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56560580681183692"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# load the iris datasets\n",
    "# fit a logistic regression model to the data\n",
    "model1 = LogisticRegression()\n",
    "model1.fit(X_train, y_train) \n",
    "model1\n",
    "model1.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================\n",
      "Testing LogisticRegression\n",
      "Learing time 0.227669000626s\n",
      "Predicting time 0.0211930274963s\n",
      "=================== Results ===================\n",
      "            Negative     Neutral     Positive\n",
      "F1       [ 0.33905579  0.44294167  0.69529229]\n",
      "Precision[ 0.44134078  0.48073394  0.62980319]\n",
      "Recall   [ 0.27526132  0.41065831  0.77598152]\n",
      "Accuracy 0.565605806812\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test,LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv(classifier, X_train, y_train):\n",
    "    log(\"===============================================\")\n",
    "    classifier_name = str(type(classifier).__name__)\n",
    "    now = time()\n",
    "    log(\"Crossvalidating \" + classifier_name + \"...\")\n",
    "    accuracy = [cross_val_score(classifier, X_train, y_train, cv=8, n_jobs=-1)]\n",
    "    log(\"Crosvalidation completed in {0}s\".format(time() - now))\n",
    "    log(\"Accuracy: \" + str(accuracy[0]))\n",
    "    log(\"Average accuracy: \" + str(np.array(accuracy[0]).mean()))\n",
    "    log(\"===============================================\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================\n",
      "Testing RandomForestClassifier\n",
      "Learing time 5.32367706299s\n",
      "Predicting time 0.245563983917s\n",
      "=================== Results ===================\n",
      "            Negative     Neutral     Positive\n",
      "F1       [ 0.25        0.45752733  0.71393158]\n",
      "Precision[ 0.52808989  0.49364791  0.62554301]\n",
      "Recall   [ 0.16376307  0.42633229  0.83140878]\n",
      "Accuracy 0.580122836404\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, RandomForestClassifier(random_state=seed,n_estimators=403,n_jobs=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
